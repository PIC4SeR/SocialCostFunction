{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "623a5f3c-43ae-432a-88c4-934a27a92df1",
   "metadata": {},
   "source": [
    "#### Scenario generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4649e547-90fd-417e-be86-30f550ffd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scenario(\n",
    "        tot_area=24, \n",
    "        res=0.2, \n",
    "        people_range=(2, 5),\n",
    "        p_per_group=(1,2),\n",
    "        area_dim=2,\n",
    "        min_dist=1,\n",
    "        group_range=(0,1)        \n",
    "        ):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    goal, q_people, q_obs, q_area = get_random_queue(tot_area, res, people_range)\n",
    "    t_people, t_obs, t_area = get_random_talking_people(tot_area, res, p_per_group, area_dim, min_dist, [q_area], group_range)\n",
    "    p_people = get_random_passing_by(tot_area, res, limit_area=t_area)\n",
    "\n",
    "    if len(q_obs) > 0:\n",
    "        obs = np.concatenate((q_obs, t_obs),axis=0)\n",
    "    else:\n",
    "        obs = t_obs\n",
    "    \n",
    "    return goal, q_people, t_people, p_people, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc2d021-5db8-4646-be58-38989169019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(goal, q_people, t_people, p_people, tot_area, res):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    m = int(tot_area/res)\n",
    "    l = int(m/2)\n",
    "    img = np.ones((m,m,3), dtype=np.uint8)*255\n",
    "    for person in q_people:\n",
    "        img[person[1]+l, person[0]+l, 0] = 0\n",
    "\n",
    "    for person in t_people:\n",
    "        img[person[1]+l, person[0]+l, 0] = 0\n",
    "\n",
    "    for person in p_people:\n",
    "        img[person[1]+l, person[0]+l, 0] = 0        \n",
    "\n",
    "    img[goal[1]+l, goal[0]+l, 1] = 0\n",
    "    \n",
    "    return np.array(img, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd7b861-5f23-43f2-a508-9335777be45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(obs, tot_area, res):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    m = int(tot_area/res)\n",
    "    l = int(m/2)\n",
    "    img = np.zeros((m,m,1))\n",
    "    for ob in obs:\n",
    "        img[ob[1]+l, ob[0]+l] = [1]\n",
    "\n",
    "    return np.array(img, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef83933-4219-4b02-9ff8-0a0d9ed94388",
   "metadata": {},
   "source": [
    "#### Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55cd040e-8a2f-4ce3-bd98-60712925d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_single_data(tot_area, res, people_range, p_per_group, area_dim, min_dist, group_range):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    goal, q_people, t_people, p_people, obs = get_scenario(tot_area, res, people_range, p_per_group, area_dim, min_dist, group_range)\n",
    "    x = get_state(goal, q_people, t_people, p_people, tot_area, res)\n",
    "    y = get_label(obs, tot_area, res)\n",
    "             \n",
    "    return [x,y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b368a23-df67-4eaa-99b2-681e30f55938",
   "metadata": {},
   "source": [
    "#### Autogenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4763c7-d483-4419-985f-5c3e8c45025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(tot_area, res, people_range, p_per_group, area_dim, min_dist, group_range, total_items=20):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < total_items:\n",
    "        x,y = gather_single_data(tot_area, res, people_range, p_per_group, area_dim, min_dist, group_range)\n",
    "        yield x, y\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0322d9f9-8b62-4c41-866d-66f36164ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_input_fn(tot_area, res, people_range, p_per_group, area_dim, min_dist, group_range, total_items=20):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: data_generator(tot_area, res, people_range, p_per_group, area_dim, min_dist, group_range, total_items),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(120,120,3), dtype=tf.uint8),\n",
    "            tf.TensorSpec(shape=(120,120,1), dtype=tf.uint8)\n",
    "        )\n",
    "    )\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d02b536f-3165-44d5-9237-4bd94b6ce65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autogenerator_dataset(tot_area, res, people_range, p_per_group, area_dim, min_dist, group_range, total_items=20):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    dataset = my_input_fn(tot_area, res, people_range, p_per_group, area_dim, min_dist, group_range, total_items)\n",
    "\n",
    "    return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
